{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with sqlite_vec\n",
    "\n",
    "This is just a toy notebook to play around with the new `sqlite_vec` extension which allows one to store vectors (e.g. embeddings) in a sqlite database and perform standard operations (such as getting the most similiar vector from a database).\n",
    "\n",
    "In this example, I we are using an artificial, toy dataset with a tweet/statement and a sentiment (harmful / not harmful).\n",
    "\n",
    "The goal of this notebook is to classify a new sentence using the `sqlite_vec` extension.\n",
    "\n",
    "Find out more about sqlite_vec [here](https://github.com/asg017/sqlite-vec)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of `sqlite_vec` and `openai`\n",
    "If necessary, you need to install `sqlite_vec` and `openai` (used to encode embeddings) first. You can do so by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlite_vec in ./venv/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.10/site-packages (1.40.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.10/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.10/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlite_vec openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Now we import the required libraries for our demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sqlite_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sqlite_vec as extension (\"setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\":memory:\") # We have an in-memory database\n",
    "db.enable_load_extension(True) # We enable loading extensions, so we can add sqlite_vec\n",
    "sqlite_vec.load(db) # We connect our database with sqlite_vec\n",
    "db.enable_load_extension(False) # We disable loading extensions (security)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small sentiment dataset and load it into the database\n",
    "Notice, that this example dataset was generated with GPT-4o and the following query:\n",
    "``\n",
    "``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    [\"Just saw the most beautiful sunset. Life is good! #blessed\", \"not hateful\"],\n",
    "    [\"I can't believe how stupid some people can be. Ugh.\", \"not hateful\"],\n",
    "    [\"I hate it when people chew with their mouths open. So gross!\", \"not hateful\"],\n",
    "    [\"Why are people so dumb these days? It's embarrassing.\", \"not hateful\"],\n",
    "    [\"Wow, can't believe how ignorant some folks are. Smh.\", \"not hateful\"],\n",
    "    [\"You're the reason this world is going to hell. So pathetic.\", \"hateful\"],\n",
    "    [\"I wish all these idiots would just disappear. World would be better.\", \"hateful\"],\n",
    "    [\"These fools need to learn their place. So sick of them.\", \"hateful\"],\n",
    "    [\"How are people so trash? They really need to stop existing.\", \"hateful\"],\n",
    "    [\"Just saw a dog on my way to work. Made my day!\", \"not hateful\"],\n",
    "    [\"I hope everyone has a wonderful day today! #positivevibes\", \"not hateful\"],\n",
    "    [\"Why are some people so annoying? Can't stand them.\", \"not hateful\"],\n",
    "    [\"Stop being so lazy and actually do something with your life.\", \"hateful\"],\n",
    "    [\"You're such a waste of space. Just go away.\", \"hateful\"],\n",
    "    [\"If you can't contribute anything, then just stay out of the way.\", \"hateful\"],\n",
    "    [\"Sending love and light to everyone today! #grateful\", \"not hateful\"],\n",
    "    [\"Can't believe the hate I'm seeing online. It's so toxic.\", \"not hateful\"],\n",
    "    [\"Why do people spread so much negativity? It's sad.\", \"not hateful\"],\n",
    "    [\"People like you make me lose faith in humanity.\", \"hateful\"],\n",
    "    [\"You don't belong here. Just leave.\", \"hateful\"],\n",
    "    [\"You're the reason why this place sucks. Go away.\", \"hateful\"],\n",
    "    [\"Woke up feeling amazing! Ready to take on the day.\", \"not hateful\"],\n",
    "    [\"Just finished a great workout. Feeling strong!\", \"not hateful\"],\n",
    "    [\"I can't stand people who think they're better than everyone else.\", \"not hateful\"],\n",
    "    [\"It's disgusting how some people think they're entitled to everything.\", \"hateful\"],\n",
    "    [\"Why are you even here? No one wants you around.\", \"hateful\"],\n",
    "    [\"If you're not going to help, then just stay out of the way.\", \"hateful\"],\n",
    "    [\"You're such a joke. No one takes you seriously.\", \"hateful\"],\n",
    "    [\"I love how supportive everyone has been. Thank you!\", \"not hateful\"],\n",
    "    [\"It's amazing how kind people can be. Restores my faith in humanity.\", \"not hateful\"],\n",
    "    [\"Some people are just too sensitive these days.\", \"not hateful\"],\n",
    "    [\"Why do people get offended by everything? It's ridiculous.\", \"not hateful\"],\n",
    "    [\"You're so weak, it's pathetic.\", \"hateful\"],\n",
    "    [\"No one cares about your opinion. Just stop talking.\", \"hateful\"],\n",
    "    [\"I don't understand why people are so rude for no reason.\", \"not hateful\"],\n",
    "    [\"Why do you even try? You're never going to be good enough.\", \"hateful\"],\n",
    "    [\"You're a failure and everyone knows it.\", \"hateful\"],\n",
    "    [\"Stop pretending to be something you're not. It's embarrassing.\", \"hateful\"],\n",
    "    [\"Had a great day with friends! Can't wait to do it again.\", \"not hateful\"],\n",
    "    [\"So grateful for all the love and support I've received.\", \"not hateful\"],\n",
    "    [\"Why can't people just mind their own business?\", \"not hateful\"],\n",
    "    [\"You're so full of yourself. It's disgusting.\", \"hateful\"],\n",
    "    [\"No one wants to hear what you have to say. Just go away.\", \"hateful\"],\n",
    "    [\"You're just a burden to everyone around you.\", \"hateful\"],\n",
    "    [\"Stop acting like you're better than everyone else.\", \"hateful\"],\n",
    "    [\"Had the best time at the concert last night!\", \"not hateful\"],\n",
    "    [\"Can't believe how amazing this weekend has been.\", \"not hateful\"],\n",
    "    [\"Why are people so obsessed with being perfect? It's exhausting.\", \"not hateful\"],\n",
    "    [\"You're such a loser. No one wants to be around you.\", \"hateful\"],\n",
    "    [\"If you disappeared, no one would even notice.\", \"hateful\"],\n",
    "    [\"You're so annoying, it's unbelievable.\", \"hateful\"],\n",
    "    [\"Why can't people just be happy for each other?\", \"not hateful\"],\n",
    "    [\"You're nothing but a waste of space.\", \"hateful\"],\n",
    "    [\"Why are you always so negative? It's bringing everyone down.\", \"not hateful\"],\n",
    "    [\"You're such a disgrace. Just leave already.\", \"hateful\"],\n",
    "    [\"No one likes you. Just face the truth.\", \"hateful\"],\n",
    "    [\"You're not worth anyone's time.\", \"hateful\"],\n",
    "    [\"Stop being so selfish and think about others for once.\", \"hateful\"],\n",
    "    [\"Had an amazing dinner with my family tonight. So grateful.\", \"not hateful\"],\n",
    "    [\"Can't believe how lucky I am to have such great friends.\", \"not hateful\"],\n",
    "    [\"You're so fake, it's pathetic.\", \"hateful\"],\n",
    "    [\"No one respects you, and for good reason.\", \"hateful\"],\n",
    "    [\"You're such a failure, it's sad.\", \"hateful\"],\n",
    "    [\"Stop trying so hard. It's not going to work.\", \"hateful\"],\n",
    "    [\"Feeling so blessed today. Life is good!\", \"not hateful\"],\n",
    "    [\"I love how supportive everyone has been lately.\", \"not hateful\"],\n",
    "    [\"You're nothing but a joke to everyone.\", \"hateful\"],\n",
    "    [\"You're just a waste of resources.\", \"hateful\"],\n",
    "    [\"No one wants you here. Just leave.\", \"hateful\"],\n",
    "    [\"Had a fantastic day at the beach. So relaxing.\", \"not hateful\"],\n",
    "    [\"Can't believe how rude some people can be.\", \"not hateful\"],\n",
    "    [\"Why do people feel the need to be so hateful?\", \"not hateful\"],\n",
    "    [\"You're the worst person I've ever met.\", \"hateful\"],\n",
    "    [\"If you left, no one would miss you.\", \"hateful\"],\n",
    "    [\"You're just a burden on society.\", \"hateful\"],\n",
    "    [\"Stop pretending like you matter. You don't.\", \"hateful\"],\n",
    "    [\"Had a great time with my family today. So much love.\", \"not hateful\"],\n",
    "    [\"Feeling so grateful for everything I have.\", \"not hateful\"],\n",
    "    [\"You're so annoying. No one likes you.\", \"hateful\"],\n",
    "    [\"Why are you even here? No one wants you around.\", \"hateful\"],\n",
    "    [\"You're just a waste of everyone's time.\", \"hateful\"],\n",
    "    [\"Why can't people just be kind to each other?\", \"not hateful\"],\n",
    "    [\"You're such a disappointment.\", \"hateful\"],\n",
    "    [\"No one cares about you. Just stop trying.\", \"hateful\"],\n",
    "    [\"Why do people have to be so cruel?\", \"not hateful\"],\n",
    "    [\"You're just a nuisance to everyone.\", \"hateful\"],\n",
    "    [\"Had an amazing weekend with friends. Can't wait to do it again.\", \"not hateful\"],\n",
    "    [\"Why can't people just mind their own business?\", \"not hateful\"],\n",
    "    [\"You're so pathetic. Just go away.\", \"hateful\"],\n",
    "    [\"No one respects you, and for good reason.\", \"hateful\"],\n",
    "    [\"Feeling so blessed to have such amazing friends.\", \"not hateful\"],\n",
    "    [\"You're such a failure. No one cares about you.\", \"hateful\"],\n",
    "    [\"Can't believe how kind people can be. It restores my faith in humanity.\", \"not hateful\"],\n",
    "    [\"You're so fake, it's embarrassing.\", \"hateful\"],\n",
    "    [\"No one wants you here. Just leave.\", \"hateful\"],\n",
    "    [\"You're just a waste of resources.\", \"hateful\"],\n",
    "    [\"Had an amazing time at the concert last night. So much fun!\", \"not hateful\"],\n",
    "    [\"You're such a loser. No one wants to be around you.\", \"hateful\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a table and load the data\n",
    "create_table_sql = \"\"\"\n",
    "    CREATE TABLE sentences(\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        sentence TEXT, -- The sentence which we want to embed\n",
    "        sentiment TEXT\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "insert_sentence_sql = \"\"\"\n",
    "    INSERT INTO sentences(sentence, sentiment) VALUES (?, ?)\n",
    "\"\"\"\n",
    "cursor = db.cursor()\n",
    "cursor.execute(create_table_sql)\n",
    "\n",
    "# Next we insert the data\n",
    "cursor.executemany(insert_sentence_sql, dataset)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the sentences using OpenAI Embeddings\n",
    "Now we embed the sentences of our example dataset using the openai model `text-embedding-3-small` (which is pretty cheap and fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your key here\n",
    "OPENAI_KEY = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "client = openai.OpenAI(api_key=OPENAI_KEY)\n",
    "embeddings = [data.embedding for data in client.embeddings.create(input = [datapoint[0] for datapoint in dataset], model = 'text-embedding-3-small').data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the embedding table using a virtual table\n",
    "We are using a virtual table here with `vec0`, the virtual table which is implemented with the `sqlite_vec` extension. \n",
    "\n",
    "Notice, that virtual table does NOT mean it is temporary. Instead, on a virtual table one can invoke callback methods of the virtual table object, such as calculating a distance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create the vector table\n",
    "import struct\n",
    "from typing import List\n",
    "\n",
    "\n",
    "create_vector_table_sql = \"\"\"\n",
    "    CREATE VIRTUAL TABLE sentences_embeddings USING vec0(\n",
    "          id INTEGER PRIMARY KEY,\n",
    "          sentence_embedding FLOAT[1536]\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "insert_embedding_sql = \"\"\"\n",
    "    INSERT INTO sentences_embeddings(sentence_embedding) VALUES (?)\n",
    "\"\"\"\n",
    "\n",
    "def serialize(vector: List[float]) -> bytes:\n",
    "    \"\"\"serializes a list of floats into a compact \"raw bytes\" format\"\"\"\n",
    "    return struct.pack(\"%sf\" % len(vector), *vector)\n",
    "\n",
    "cursor = db.cursor()\n",
    "cursor.execute(create_vector_table_sql)\n",
    "cursor.executemany(insert_embedding_sql, [(serialize(embedding), ) for embedding in embeddings])\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify a new sentence\n",
    "Now we create a new sample which we want to classify with the help of our sqlite database.\n",
    "First, we embed it again using the same model as previously (`text-embedding-3-small`) and then we use the\n",
    "\n",
    "```\n",
    "sentence_embedding MATCH ([1, 0.231, 0.31232, ...])\n",
    "AND k = 3\n",
    "```\n",
    "\n",
    "syntax.\n",
    "\n",
    "Like this we get the three (determined by the `k` parameter in the query) closest embeddings to our new sample.\n",
    "We then can just return the same classification of the closest sentences in our database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we try to classify one new sentence\n",
    "sentence_to_classify = \"I hate you and I hope you never talk to me again!\"\n",
    "sentence_to_classify_embedded = client.embeddings.create(input = sentence_to_classify, model = 'text-embedding-3-small').data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_closest_sentiment_from_database_sql = \"\"\"\n",
    "    SELECT sentence, sentiment, distance\n",
    "    FROM sentences_embeddings\n",
    "    LEFT JOIN sentences ON sentences.id = sentences_embeddings.id\n",
    "    WHERE sentences_embeddings.sentence_embedding MATCH ?\n",
    "    AND k = 3 -- kNN\n",
    "    ORDER BY distance\n",
    "\"\"\"\n",
    "\n",
    "cursor = db.cursor()\n",
    "resultset = cursor.execute(get_closest_sentiment_from_database_sql, (serialize(sentence_to_classify_embedded),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"You're the worst person I've ever met.\", 'hateful', 1.043708086013794)\n",
      "(\"You're so annoying. No one likes you.\", 'hateful', 1.1006056070327759)\n",
      "(\"You're such a loser. No one wants to be around you.\", 'hateful', 1.1094571352005005)\n"
     ]
    }
   ],
   "source": [
    "for result in resultset:\n",
    "    print(result)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we would classify our new sample as hateful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
